{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a8162ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH: None\n",
      "PATH: c:\\Users\\gases\\.conda\\envs\\python_3_7;C:\\Users\\gases\\.conda\\envs\\python_3_7;C:\\Users\\gases\\.conda\\envs\\python_3_7\\Library\\mingw-w64\\bin;C:\\Users\\gases\\.conda\\envs\\python_3_7\\Library\\usr\\bin;C:\\Users\\gases\\.conda\\envs\\python_3_7\\Library\\bin;C:\\Users\\gases\\.conda\\envs\\python_3_7\\Scripts;C:\\Users\\gases\\.conda\\envs\\python_3_7\\bin;C:\\ProgramData\\Anaconda3\\condabin;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PyQt5\\Qt5\\bin;C:\\ProgramData\\Anaconda3;C:\\ProgramData\\Anaconda3\\Library\\mingw-w64\\bin;C:\\ProgramData\\Anaconda3\\Library\\usr\\bin;C:\\ProgramData\\Anaconda3\\Library\\bin;C:\\ProgramData\\Anaconda3\\Scripts;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\libnvvp;.;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2020.3.0;C:\\Users\\gases\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin;C:\\Users\\gases\\AppData\\Local\\Programs\\Microsoft VS Code\\bin;C:\\Users\\gases\\.conda\\envs\\python_3_7;C:\\Users\\gases\\.conda\\envs\\python_3_7\\Library\\mingw-w64\\bin;C:\\Users\\gases\\.conda\\envs\\python_3_7\\Library\\usr\\bin;C:\\Users\\gases\\.conda\\envs\\python_3_7\\Library\\bin;C:\\Users\\gases\\.conda\\envs\\python_3_7\\Scripts;C:\\Users\\gases\\.conda\\envs\\python_3_7\\bin;C:\\ProgramData\\Anaconda3\\condabin;C:\\ProgramData\\Anaconda3\\lib\\site-packages\\PyQt5\\Qt5\\bin;C:\\ProgramData\\Anaconda3;C:\\ProgramData\\Anaconda3\\Library\\mingw-w64\\bin;C:\\ProgramData\\Anaconda3\\Library\\usr\\bin;C:\\ProgramData\\Anaconda3\\Library\\bin;C:\\ProgramData\\Anaconda3\\Scripts;C:\\Program Files\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\libnvvp;.;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\Nsight Compute 2020.3.0;C:\\Users\\gases\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin;C:\\Users\\gases\\AppData\\Local\\Programs\\Microsoft VS Code\\bin\n",
      "0.11.2\n",
      "1.9.1\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "print(\"PYTHONPATH:\", os.environ.get('PYTHONPATH'))\n",
    "print(\"PATH:\", os.environ.get('PATH'))\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import phate\n",
    "import math\n",
    "import random\n",
    "import gc\n",
    "import scprep\n",
    "from datetime import datetime, time\n",
    "from matplotlib.animation import ImageMagickWriter\n",
    "import matplotlib.animation as animation\n",
    "import zipfile\n",
    "from urllib.request import urlopen\n",
    "import scipy.stats as st\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.stats import kde\n",
    "from scipy.stats import binned_statistic\n",
    "from scipy.stats import f_oneway\n",
    "from matplotlib.colors import LogNorm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "print(sns.__version__)\n",
    "from anndata import AnnData\n",
    "import scanpy as sc\n",
    "from delve import *\n",
    "import anndata as ad\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from kh import sketch\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "print(sc.__version__)\n",
    "today = datetime.now().strftime(\"%m%d%Y-%H%M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9229c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### full_dir should be the directory that contains the output of your \"calculate cell properties\" notebook. Called cell_data by default\n",
    "### well_list should be every well in the dataset that you intend to combine into a single adata object for analysis\n",
    "\n",
    "full_dir = r'path\\to\\my\\data'\n",
    "well_list = ['B02','B03','B04','B05', 'B06', 'B07', 'B08', 'B09', 'B10', 'B11']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d6efbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition to Normalize the dataframe by z-score\n",
    "\n",
    "def standardizeColumns(df):\n",
    "    df = df.copy()\n",
    "    df.iloc[:,:] = df.iloc[:,:].apply(lambda x: (x-x.mean())/ x.std(), axis=0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383418ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Builds a dataframe for each well defined in well_list, then outputs the length of that list. The number output is how many cells\n",
    "#were found in the well\n",
    "\n",
    "fullest_df = pd.DataFrame()\n",
    "for well in well_list:\n",
    "    print(f'starting Well {well}')\n",
    "    full_df = pd.read_csv(os.path.join(full_dir,f'cell_data_{well}_df.csv'), sep=',') \n",
    "\n",
    "   ### This part here is optional, you can add important metadata information at this step. Treatment and Sample ID are shown as examples\n",
    "    if '2' in well and ('B' in well or 'C' in well):\n",
    "        full_df['treatment'] = 'control' \n",
    "        full_df['sample_ID'] = 1\n",
    "    if '3' in well and ('B' in well or 'C' in well):\n",
    "       full_df['treatment'] = '2day' \n",
    "       full_df['sample_ID'] = 2\n",
    "    if '4' in well and ('B' in well or 'C' in well):\n",
    "       full_df['treatment'] = '5day' \n",
    "       full_df['sample_ID'] = 3\n",
    "    if '5' in well and ('B' in well or 'C' in well):\n",
    "       full_df['treatment'] = '9day' \n",
    "       full_df['sample_ID'] = 4\n",
    "    if '6' in well and ('B' in well or 'C' in well):\n",
    "       full_df['treatment'] = '11day' \n",
    "       full_df['sample_ID'] = 5\n",
    "    if '7' in well and ('B' in well or 'C' in well):\n",
    "       full_df['treatment'] = '13day' \n",
    "       full_df['sample_ID'] = 6\n",
    "    if '8' in well and ('B' in well or 'C' in well):\n",
    "       full_df['treatment'] = '15day' \n",
    "       full_df['sample_ID'] = 7\n",
    "    if '9' in well and ('B' in well or 'C' in well):\n",
    "       full_df['treatment'] = '17day' \n",
    "       full_df['sample_ID'] = 8\n",
    "    if '10' in well and ('B' in well or 'C' in well):\n",
    "       full_df['treatment'] = '20day' \n",
    "       full_df['sample_ID'] = 9\n",
    "    if '11' in well and ('B' in well or 'C' in well):\n",
    "       full_df['treatment'] = '22day' \n",
    "       full_df['sample_ID'] = 10\n",
    "    if '2' in well and ('D' in well or 'E' in well):\n",
    "       full_df['treatment'] = '24day' \n",
    "       full_df['sample_ID'] = 11\n",
    "    if '3' in well and ('D' in well or 'E' in well):\n",
    "       full_df['treatment'] = '27day' \n",
    "       full_df['sample_ID'] = 12\n",
    "    if '4' in well and ('D' in well or 'E' in well):\n",
    "       full_df['treatment'] = '29day' \n",
    "       full_df['sample_ID'] = 13\n",
    "    if '5' in well and ('D' in well or 'E' in well):\n",
    "       full_df['treatment'] = '31day' \n",
    "       full_df['sample_ID'] = 14\n",
    "       \n",
    "    exec(f'well{well}_df = full_df.copy()')\n",
    "    fullest_df = pd.concat([fullest_df, full_df], ignore_index = True)\n",
    "    print(len(full_df))\n",
    "    print(len(fullest_df))\n",
    "\n",
    "### You may find that you need to force some of the columns added this way into specific data types. You can do that here.\n",
    "# Convert sample_ID column to categorical data type\n",
    "fullest_df['sample_ID'] = fullest_df['sample_ID'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab86f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### It is good practice to save these dataframes at key steps, such as this one\n",
    "fullest_df.to_csv(r'path\\to\\my\\data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6f71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns that you don't need - Preparation for conversion to AnnData object\n",
    "fullest_df = fullest_df.drop(columns=[\"Unnamed: 0\", \"bbox-0\", \"bbox-1\", \"bbox-2\", etc...])\n",
    "# Extract metadata columns and store them in a separate dataframe\n",
    "metadata = fullest_df[[\"label\", \"well\", \"sample_ID\", \"treatment\"]]\n",
    "# Remove metadata columns from the main dataframe\n",
    "fullest_df = fullest_df.drop(columns=[\"label\", \"well\", \"sample_ID\", \"treatment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d82c0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Z normalize the data\n",
    "standard_df = standardizeColumns(fullest_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdec0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#min-max normalize the data - Not used in this example, provided for potential use\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(fullest_df)\n",
    "normalized_data = pd.DataFrame(normalized_data, index = fullest_df.index, columns = fullest_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f844a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the pandas dataframe to an anndata object\n",
    "standard_adata = ad.AnnData(standard_df)\n",
    "# Add metadata back to the anndata object\n",
    "standard_adata.obs = metadata.copy()\n",
    "standard_adata.obs_names = [f'c_{i}' for i in standard_adata.obs_names]\n",
    "\n",
    "#Save the entire adata file\n",
    "adata_save_path = r'my\\save\\path\\standard_adata.h5ad'\n",
    "standard_adata.write_h5ad(adata_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9042b42c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Sketching lets your subsample your data accurately. \n",
    "### This example groups for subsampling based on the sample_id metadata\n",
    "\n",
    "idx, standard_adata_sub = sketch(standard_adata, num_subsamples = 1200, frequency_seed = 42, sample_set_key = 'sample_ID')\n",
    "#Save the entire adata file\n",
    "adata_save_path = r'my\\save\\path\\standard_adata_sub_sub.h5ad'\n",
    "standard_adata_sub.write_h5ad(adata_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338619b",
   "metadata": {},
   "source": [
    "Subsequent notebooks will load in the saved adata file of your choice, either the full dataset of the subsampled dataset.\n",
    "Additionally, you can produce any desired normalized or non-normalized adata file here. Z-score normalized is the provided example, but other methods can be used with minor modifications. i.e. min-max normalization using the provided code."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
